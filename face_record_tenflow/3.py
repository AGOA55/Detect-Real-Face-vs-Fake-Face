import cv2
import os
import numpy as np
import pickle
import shutil
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import regularizers
import time

# --- Global Settings ---
dataset_path = r'E:\Project By Tawan\dectect face\face_record_tenflow\data02' # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á path ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
camera_index = 0
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
img_size = (100, 100)

# Global threshold variables (‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏Ç‡∏∂‡πâ‡∏ô)
CONFIDENCE_THRESHOLD = 88.0
MIN_CONFIDENCE_GAP = 15.0
MIN_STABILITY_FRAMES = 3

class FaceTracker:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô"""
    def __init__(self, face_id, initial_bbox, max_missing_frames=10):
        self.face_id = face_id
        self.bbox = initial_bbox  # (x, y, w, h)
        self.center = self._get_center(initial_bbox)
        self.prediction_buffer = []
        self.missing_frames = 0
        self.max_missing_frames = max_missing_frames
        self.last_seen = time.time()
        self.is_stable = False
        self.confirmed_identity = None
        self.confidence_history = []
        
    def _get_center(self, bbox):
        x, y, w, h = bbox
        return (x + w//2, y + h//2)
    
    def update(self, new_bbox):
        """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
        self.bbox = new_bbox
        self.center = self._get_center(new_bbox)
        self.missing_frames = 0
        self.last_seen = time.time()
    
    def add_prediction(self, label_idx, confidence, confidence_gap):
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà"""
        self.prediction_buffer.append({
            'label': label_idx,
            'confidence': confidence,
            'gap': confidence_gap,
            'timestamp': time.time()
        })
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏Ñ‡πà 10 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        if len(self.prediction_buffer) > 10:
            self.prediction_buffer.pop(0)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
        self._check_stability()
    
    def _check_stability(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"""
        if len(self.prediction_buffer) < MIN_STABILITY_FRAMES:
            return
        
        recent_predictions = self.prediction_buffer[-MIN_STABILITY_FRAMES:]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        labels = [p['label'] for p in recent_predictions]
        confidences = [p['confidence'] for p in recent_predictions]
        gaps = [p['gap'] for p in recent_predictions]
        
        # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ label
        from collections import Counter
        label_counts = Counter(labels)
        most_common_label, count = label_counts.most_common(1)[0]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
        stability_ratio = count / len(recent_predictions)
        avg_confidence = np.mean([c for i, c in enumerate(confidences) if labels[i] == most_common_label])
        avg_gap = np.mean([g for i, g in enumerate(gaps) if labels[i] == most_common_label])
        
        # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô
        self.is_stable = (
            stability_ratio >= 0.7 and  # ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 70% ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô label ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            avg_confidence >= CONFIDENCE_THRESHOLD and
            avg_gap >= MIN_CONFIDENCE_GAP
        )
        
        if self.is_stable:
            self.confirmed_identity = most_common_label
            self.confidence_history = confidences[-3:]
        else:
            self.confirmed_identity = None
    
    def get_display_info(self, le):
        """‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
        if not self.is_stable or self.confirmed_identity is None:
            return "Unknown", (0, 0, 255), 0.0
        
        name = le.inverse_transform([self.confirmed_identity])[0]
        avg_confidence = np.mean(self.confidence_history)
        color = (0, 255, 0)
        
        return name, color, avg_confidence
    
    def distance_to(self, bbox):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà"""
        new_center = self._get_center(bbox)
        return np.sqrt((self.center[0] - new_center[0])**2 + (self.center[1] - new_center[1])**2)

def is_good_quality_image(image, min_variance=80):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏û"""
    variance = cv2.Laplacian(image, cv2.CV_64F).var()
    return variance > min_variance

def capture_faces():
    person_name = input("Enter the person's name (no spaces): ").strip()
    if not person_name:
        print("‚ùå Invalid name.")
        return

    save_path = os.path.join(dataset_path, person_name)
    
    try:
        os.makedirs(save_path, exist_ok=True)
        print(f"üìÅ Directory ready: {save_path}")
    except Exception as e:
        print(f"‚ùå Error creating directory: {e}")
        return

    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        print("‚ùå Error: Could not open webcam.")
        return

    print(f"\nüì∑ Capturing faces for '{person_name}'...")
    print("üí° Tips: Move your head slightly, change expressions, different angles")
    print("Press 'q' to quit early")
    
    count = 0
    samples_to_take = 300
    skip_frames = 0

    while count < samples_to_take:
        ret, frame = cap.read()
        if not ret:
            break

        skip_frames += 1
        if skip_frames < 3:
            continue
        skip_frames = 0

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))

        if len(faces) > 0:
            faces = sorted(faces, key=lambda f: f[2]*f[3], reverse=True)
            (x, y, w, h) = faces[0]
            
            face_roi = gray[y:y+h, x:x+w]
            
            if is_good_quality_image(face_roi, min_variance=60):
                face_img = cv2.resize(face_roi, img_size)
                face_img = cv2.equalizeHist(face_img)
                
                file_path = os.path.join(save_path, f"{count+1:03d}.jpg")
                cv2.imwrite(file_path, face_img)
                count += 1

                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, f"Captured: {count}/{samples_to_take}", (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            else:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 165, 255), 2)
                cv2.putText(frame, "Poor quality", (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)

        progress = int((count / samples_to_take) * 100)
        cv2.putText(frame, f"Progress: {progress}%", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        cv2.imshow("Capturing Faces", frame)
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print(f"‚úÖ Collected {count} images for '{person_name}'.")

def train_model():
    print("\nüîÑ Loading dataset and training model...")
    X, y = [], []

    if not os.path.exists(dataset_path) or not os.listdir(dataset_path):
        print("‚ùå Dataset is empty. Please capture faces first.")
        return

    print("üìä Loading images...")
    for folder_name in os.listdir(dataset_path):
        folder_path = os.path.join(dataset_path, folder_name)
        if not os.path.isdir(folder_path):
            continue

        folder_images = 0
        for file_name in os.listdir(folder_path):
            img_path = os.path.join(folder_path, file_name)
            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                continue

            image = cv2.resize(image, img_size)
            image = cv2.equalizeHist(image)
            X.append(image)
            y.append(folder_name)
            folder_images += 1
        
        print(f"‚úÖ Loaded {folder_images} images for '{folder_name}'")

    if len(X) < 100:
        print("‚ùå Need at least 100 images total for training.")
        return

    X = np.array(X).reshape(-1, img_size[0], img_size[1], 1).astype('float32') / 255.0

    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    y_categorical = to_categorical(y_encoded)

    X_train, X_val, y_train, y_val = train_test_split(
        X, y_categorical, test_size=0.25, random_state=42, stratify=y_encoded
    )

    print(f"üìà Training data: {len(X_train)}, Validation data: {len(X_val)}")

    datagen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.05,
        height_shift_range=0.05,
        zoom_range=0.05,
        horizontal_flip=False,
        fill_mode='nearest'
    )

    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1),
               kernel_regularizer=regularizers.l2(0.001)),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        Conv2D(64, (3, 3), activation='relu',
               kernel_regularizer=regularizers.l2(0.001)),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        Conv2D(128, (3, 3), activation='relu',
               kernel_regularizer=regularizers.l2(0.001)),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        Flatten(),
        Dense(256, activation='relu',
              kernel_regularizer=regularizers.l2(0.001)),
        Dropout(0.5),
        Dense(len(le.classes_), activation='softmax')
    ])

    model.compile(
        optimizer=Adam(learning_rate=0.0005),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    early_stop = EarlyStopping(
        monitor='val_accuracy',
        patience=8,
        restore_best_weights=True,
        verbose=1
    )
    
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=0.00001,
        verbose=1
    )

    print("üöÄ Training model...")
    history = model.fit(
        datagen.flow(X_train, y_train, batch_size=8),
        epochs=30,
        validation_data=(X_val, y_val),
        callbacks=[early_stop, reduce_lr],
        verbose=1
    )

    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    print(f"\n‚úÖ Final Validation Accuracy: {val_acc*100:.2f}%")

    if val_acc >= 0.90:
        print("üéâ Excellent accuracy!")
    elif val_acc >= 0.80:
        print("üëç Good accuracy!")
    else:
        print("‚ö†Ô∏è  Consider collecting more varied data.")

    model.save("face_recognition_model.keras")
    with open("label_encoder.pkl", "wb") as f:
        pickle.dump(le, f)

    print("‚úÖ Training complete. Model saved.")

def recognize_faces():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    global CONFIDENCE_THRESHOLD, MIN_CONFIDENCE_GAP
    
    try:
        model = load_model("face_recognition_model.keras")
        with open("label_encoder.pkl", "rb") as f:
            le = pickle.load(f)
    except FileNotFoundError:
        print("‚ùå Model not found. Train the model first.")
        return

    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        print("‚ùå Error: Could not open webcam.")
        return

    print("üü¢ Enhanced multi-person recognition started!")
    print(f"üéöÔ∏è  Confidence threshold: {CONFIDENCE_THRESHOLD}%")
    print(f"üéöÔ∏è  Confidence gap threshold: {MIN_CONFIDENCE_GAP}%")
    print("Press 'q' to quit")
    
    face_trackers = []
    next_face_id = 0
    max_distance_threshold = 80  # ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏• ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))
        
        current_time = time.time()
        
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó missing frames ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö tracker ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        for tracker in face_trackers[:]:
            tracker.missing_frames += 1
            if tracker.missing_frames > tracker.max_missing_frames:
                face_trackers.remove(tracker)
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Å‡∏±‡∏ö tracker ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        matched_faces = set()
        
        for face_bbox in faces:
            best_tracker = None
            min_distance = float('inf')
            
            # ‡∏´‡∏≤ tracker ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            for tracker in face_trackers:
                distance = tracker.distance_to(face_bbox)
                if distance < min_distance and distance < max_distance_threshold:
                    min_distance = distance
                    best_tracker = tracker
            
            if best_tracker:
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó tracker ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                best_tracker.update(face_bbox)
                matched_faces.add(id(best_tracker))
            else:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á tracker ‡πÉ‡∏´‡∏°‡πà
                new_tracker = FaceTracker(next_face_id, face_bbox)
                face_trackers.append(new_tracker)
                next_face_id += 1
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô
        for tracker in face_trackers:
            if tracker.missing_frames > 0:  # ‡∏Ç‡πâ‡∏≤‡∏° tracker ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏ô‡∏µ‡πâ
                continue
                
            x, y, w, h = tracker.bbox
            face_roi = gray[y:y+h, x:x+w]
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
            if not is_good_quality_image(face_roi, min_variance=50):
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 165, 255), 2)
                cv2.putText(frame, f"Poor Quality (ID:{tracker.face_id})", (x, y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
                continue

            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model
            face_roi = cv2.resize(face_roi, img_size)
            face_roi = cv2.equalizeHist(face_roi)
            face_roi = face_roi.reshape(1, img_size[0], img_size[1], 1).astype('float32') / 255.0

            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
            predictions = model.predict(face_roi, verbose=0)
            confidence = np.max(predictions) * 100
            label_idx = np.argmax(predictions)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence gap
            sorted_predictions = np.sort(predictions[0])[::-1]
            confidence_gap = (sorted_predictions[0] - sorted_predictions[1]) * 100 if len(sorted_predictions) > 1 else confidence
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡∏á tracker
            tracker.add_prediction(label_idx, confidence, confidence_gap)
            
            # ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            name, color, avg_confidence = tracker.get_display_info(le)
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)
            
            if name == "Unknown":
                label = f"Unknown (ID:{tracker.face_id})"
                detail = f"Conf: {confidence:.1f}% | Gap: {confidence_gap:.1f}%"
            else:
                label = f"{name} (ID:{tracker.face_id})"
                detail = f"Avg: {avg_confidence:.1f}% | Stable: {'‚úì' if tracker.is_stable else '‚úó'}"
            
            cv2.putText(frame, label, (x, y - 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            cv2.putText(frame, detail, (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö
        cv2.putText(frame, f"Active Trackers: {len(face_trackers)}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"Threshold: {CONFIDENCE_THRESHOLD}% | Gap: {MIN_CONFIDENCE_GAP}%", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, "Press 'q' to quit", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        cv2.imshow("Enhanced Face Recognition", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("üî¥ Recognition stopped.")
            break

    cap.release()
    cv2.destroyAllWindows()

def delete_person_data():
    if not os.path.exists(dataset_path) or not os.listdir(dataset_path):
        print("‚ùå Dataset is empty.")
        return
    
    print("\nüìÅ Available persons:")
    persons = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
    for i, person in enumerate(persons, 1):
        img_count = len([f for f in os.listdir(os.path.join(dataset_path, person)) 
                        if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"{i}. {person} ({img_count} images)")
    
    person_name = input("\nEnter the person's name to delete: ").strip()
    person_path = os.path.join(dataset_path, person_name)

    if os.path.exists(person_path):
        confirm = input(f"‚ö†Ô∏è  Are you sure you want to delete '{person_name}'? (y/n): ")
        if confirm.lower() == 'y':
            try:
                shutil.rmtree(person_path)
                print(f"‚úÖ Deleted data for '{person_name}'. Please retrain the model.")
                
                if os.path.exists("face_recognition_model.keras"):
                    delete_model = input("Delete trained model too? (y/n): ")
                    if delete_model.lower() == 'y':
                        os.remove("face_recognition_model.keras")
                        if os.path.exists("label_encoder.pkl"):
                            os.remove("label_encoder.pkl")
                        print("üóëÔ∏è  Model files deleted too.")
                        
            except Exception as e:
                print(f"‚ùå Error deleting: {e}")
        else:
            print("‚ùå Deletion cancelled.")
    else:
        print("‚ùå Person not found in dataset.")

def view_dataset():
    if not os.path.exists(dataset_path) or not os.listdir(dataset_path):
        print("‚ùå Dataset is empty.")
        return
    
    print("\n" + "="*60)
    print("üìä DATASET SUMMARY")
    print("="*60)
    
    total_images = 0
    total_persons = 0
    min_images = float('inf')
    max_images = 0
    
    for folder_name in os.listdir(dataset_path):
        folder_path = os.path.join(dataset_path, folder_name)
        if os.path.isdir(folder_path):
            img_count = len([f for f in os.listdir(folder_path) 
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            
            status = ""
            if img_count >= 200:
                status = "üü¢ Excellent"
            elif img_count >= 100:
                status = "üü° Good"
            else:
                status = "üî¥ Need more"
            
            print(f"üë§ {folder_name:15} : {img_count:3d} images {status}")
            
            total_images += img_count
            total_persons += 1
            min_images = min(min_images, img_count)
            max_images = max(max_images, img_count)
    
    print("="*60)
    print(f"üìà Total persons  : {total_persons}")
    print(f"üìà Total images   : {total_images}")
    if total_persons > 0:
        print(f"üìä Average/person : {total_images//total_persons}")
        print(f"üìä Min images     : {min_images}")
        print(f"üìä Max images     : {max_images}")
    
    print("="*60)
    
    if total_images < 200:
        print("üí° Recommendation: Collect at least 200+ images per person")
    elif any(len([f for f in os.listdir(os.path.join(dataset_path, d)) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) < 100 
            for d in os.listdir(dataset_path) 
            if os.path.isdir(os.path.join(dataset_path, d))):
        print("üí° Recommendation: Some persons need more images")
    else:
        print("‚úÖ Dataset looks good for training!")

def test_model():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö model ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ"""
    try:
        model = load_model("face_recognition_model.keras")
        with open("label_encoder.pkl", "rb") as f:
            le = pickle.load(f)
    except FileNotFoundError:
        print("‚ùå Model not found. Train the model first.")
        return

    if not os.path.exists(dataset_path):
        print("‚ùå Dataset not found.")
        return
    
    print("\nüß™ Testing model with dataset images...")
    
    correct = 0
    total = 0
    
    for person_name in os.listdir(dataset_path):
        person_path = os.path.join(dataset_path, person_name)
        if not os.path.isdir(person_path):
            continue
            
        person_correct = 0
        person_total = 0
        
        images = [f for f in os.listdir(person_path) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        test_images = np.random.choice(images, min(10, len(images)), replace=False)
        
        for img_name in test_images:
            img_path = os.path.join(person_path, img_name)
            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            
            if image is None:
                continue
                
            image = cv2.resize(image, img_size)
            image = cv2.equalizeHist(image)
            image = image.reshape(1, img_size[0], img_size[1], 1).astype('float32') / 255.0
            
            predictions = model.predict(image, verbose=0)
            confidence = np.max(predictions) * 100
            predicted_idx = np.argmax(predictions)
            predicted_name = le.inverse_transform([predicted_idx])[0]
            
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á
            if predicted_name == person_name and confidence >= CONFIDENCE_THRESHOLD:
                correct += 1
                person_correct += 1
            
            total += 1
            person_total += 1
        
        accuracy = (person_correct/person_total)*100 if person_total > 0 else 0
        print(f"üë§ {person_name:15} : {person_correct:2d}/{person_total:2d} = {accuracy:5.1f}%")
    
    overall_accuracy = (correct/total)*100 if total > 0 else 0
    print("="*50)
    print(f"üéØ Overall Test Accuracy: {correct}/{total} = {overall_accuracy:.1f}%")
    
    if overall_accuracy >= 90:
        print("üéâ Excellent performance!")
    elif overall_accuracy >= 80:
        print("üëç Good performance!")
    else:
        print("‚ö†Ô∏è  Model needs improvement. Consider:")
        print("   ‚Ä¢ Collecting more varied images")
        print("   ‚Ä¢ Retraining with different parameters")

def adjust_threshold():
    """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    global CONFIDENCE_THRESHOLD, MIN_CONFIDENCE_GAP
    
    print("\n‚öôÔ∏è  THRESHOLD ADJUSTMENT")
    print("="*50)
    print("Higher confidence threshold = More strict recognition")
    print("Higher gap threshold = Better unknown detection")
    print("="*50)
    
    print(f"üìä Current confidence threshold: {CONFIDENCE_THRESHOLD}%")
    print(f"üìä Current confidence gap threshold: {MIN_CONFIDENCE_GAP}%")
    
    try:
        print("\n1. Adjust confidence threshold")
        print("2. Adjust confidence gap threshold") 
        print("3. Reset to defaults")
        choice = input("Choose option (1-3): ").strip()
        
        if choice == '1':
            new_threshold = input(f"Enter new confidence threshold (70-99) or 'q' to cancel: ").strip()
            if new_threshold.lower() != 'q':
                new_threshold = float(new_threshold)
                if 70 <= new_threshold <= 99:
                    CONFIDENCE_THRESHOLD = new_threshold
                    print(f"‚úÖ Confidence threshold updated to {CONFIDENCE_THRESHOLD}%")
                else:
                    print("‚ùå Invalid threshold. Must be between 70-99")
                    
        elif choice == '2':
            new_gap = input(f"Enter new confidence gap threshold (5-30) or 'q' to cancel: ").strip()
            if new_gap.lower() != 'q':
                new_gap = float(new_gap)
                if 5 <= new_gap <= 30:
                    MIN_CONFIDENCE_GAP = new_gap
                    print(f"‚úÖ Confidence gap threshold updated to {MIN_CONFIDENCE_GAP}%")
                else:
                    print("‚ùå Invalid gap threshold. Must be between 5-30")
                    
        elif choice == '3':
            CONFIDENCE_THRESHOLD = 88.0
            MIN_CONFIDENCE_GAP = 15.0
            print("‚úÖ Thresholds reset to defaults")
            
    except ValueError:
        print("‚ùå Invalid input. Please enter a number.")

def live_adjustment():
    """‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÅ‡∏ö‡∏ö real-time ‡∏Ç‡∏ì‡∏∞‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    global CONFIDENCE_THRESHOLD, MIN_CONFIDENCE_GAP
    
    try:
        model = load_model("face_recognition_model.keras")
        with open("label_encoder.pkl", "rb") as f:
            le = pickle.load(f)
    except FileNotFoundError:
        print("‚ùå Model not found. Train the model first.")
        return

    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        print("‚ùå Error: Could not open webcam.")
        return

    print("üéöÔ∏è  LIVE THRESHOLD ADJUSTMENT")
    print("Controls:")
    print("  W/S = Confidence threshold ‚Üë‚Üì")
    print("  A/D = Gap threshold ‚Üë‚Üì") 
    print("  Q = Quit")
    
    face_trackers = []
    next_face_id = 0
    max_distance_threshold = 80
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))
        
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó missing frames
        for tracker in face_trackers[:]:
            tracker.missing_frames += 1
            if tracker.missing_frames > tracker.max_missing_frames:
                face_trackers.remove(tracker)
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        for face_bbox in faces:
            best_tracker = None
            min_distance = float('inf')
            
            for tracker in face_trackers:
                distance = tracker.distance_to(face_bbox)
                if distance < min_distance and distance < max_distance_threshold:
                    min_distance = distance
                    best_tracker = tracker
            
            if best_tracker:
                best_tracker.update(face_bbox)
            else:
                new_tracker = FaceTracker(next_face_id, face_bbox)
                face_trackers.append(new_tracker)
                next_face_id += 1
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        for tracker in face_trackers:
            if tracker.missing_frames > 0:
                continue
                
            x, y, w, h = tracker.bbox
            face_roi = gray[y:y+h, x:x+w]
            
            if is_good_quality_image(face_roi, min_variance=50):
                face_roi = cv2.resize(face_roi, img_size)
                face_roi = cv2.equalizeHist(face_roi)
                face_roi = face_roi.reshape(1, img_size[0], img_size[1], 1).astype('float32') / 255.0

                predictions = model.predict(face_roi, verbose=0)
                confidence = np.max(predictions) * 100
                label_idx = np.argmax(predictions)
                
                sorted_predictions = np.sort(predictions[0])[::-1]
                confidence_gap = (sorted_predictions[0] - sorted_predictions[1]) * 100 if len(sorted_predictions) > 1 else confidence
                
                tracker.add_prediction(label_idx, confidence, confidence_gap)
                name, color, avg_confidence = tracker.get_display_info(le)

                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)
                
                if name == "Unknown":
                    label = f"Unknown (ID:{tracker.face_id})"
                    detail = f"C:{confidence:.1f}% G:{confidence_gap:.1f}%"
                else:
                    label = f"{name} (ID:{tracker.face_id})"
                    detail = f"Avg:{avg_confidence:.1f}%"
                
                cv2.putText(frame, label, (x, y - 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                cv2.putText(frame, detail, (x, y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö
        cv2.putText(frame, f"Conf Threshold: {CONFIDENCE_THRESHOLD:.1f}%", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"Gap Threshold: {MIN_CONFIDENCE_GAP:.1f}%", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, "W/S=Conf, A/D=Gap, Q=Quit", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        cv2.imshow("Live Threshold Adjustment", frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('w') and CONFIDENCE_THRESHOLD < 99:
            CONFIDENCE_THRESHOLD += 1.0
            print(f"üî∫ Confidence Threshold: {CONFIDENCE_THRESHOLD}%")
        elif key == ord('s') and CONFIDENCE_THRESHOLD > 70:
            CONFIDENCE_THRESHOLD -= 1.0
            print(f"üîª Confidence Threshold: {CONFIDENCE_THRESHOLD}%")
        elif key == ord('d') and MIN_CONFIDENCE_GAP < 30:
            MIN_CONFIDENCE_GAP += 1.0
            print(f"üî∫ Gap Threshold: {MIN_CONFIDENCE_GAP}%")
        elif key == ord('a') and MIN_CONFIDENCE_GAP > 5:
            MIN_CONFIDENCE_GAP -= 1.0
            print(f"üîª Gap Threshold: {MIN_CONFIDENCE_GAP}%")

    cap.release()
    cv2.destroyAllWindows()
    print(f"‚úÖ Thresholds set to: Confidence={CONFIDENCE_THRESHOLD}%, Gap={MIN_CONFIDENCE_GAP}%")

def advanced_test():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ö‡∏ö advanced ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á confusion matrix"""
    try:
        model = load_model("face_recognition_model.keras")
        with open("label_encoder.pkl", "rb") as f:
            le = pickle.load(f)
    except FileNotFoundError:
        print("‚ùå Model not found. Train the model first.")
        return

    if not os.path.exists(dataset_path):
        print("‚ùå Dataset not found.")
        return
    
    print("\nüî¨ ADVANCED MODEL TESTING")
    print("="*50)
    
    all_true_labels = []
    all_pred_labels = []
    all_confidences = []
    
    for person_name in os.listdir(dataset_path):
        person_path = os.path.join(dataset_path, person_name)
        if not os.path.isdir(person_path):
            continue
            
        images = [f for f in os.listdir(person_path) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 20 ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô
        test_images = np.random.choice(images, min(20, len(images)), replace=False)
        
        for img_name in test_images:
            img_path = os.path.join(person_path, img_name)
            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            
            if image is None:
                continue
                
            image = cv2.resize(image, img_size)
            image = cv2.equalizeHist(image)
            image = image.reshape(1, img_size[0], img_size[1], 1).astype('float32') / 255.0
            
            predictions = model.predict(image, verbose=0)
            confidence = np.max(predictions) * 100
            predicted_idx = np.argmax(predictions)
            predicted_name = le.inverse_transform([predicted_idx])[0]
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç confidence gap
            sorted_predictions = np.sort(predictions[0])[::-1]
            confidence_gap = (sorted_predictions[0] - sorted_predictions[1]) * 100 if len(sorted_predictions) > 1 else confidence
            
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î
            if confidence >= CONFIDENCE_THRESHOLD and confidence_gap >= MIN_CONFIDENCE_GAP:
                final_prediction = predicted_name
            else:
                final_prediction = "Unknown"
            
            all_true_labels.append(person_name)
            all_pred_labels.append(final_prediction)
            all_confidences.append(confidence)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics
    from collections import defaultdict
    confusion_matrix = defaultdict(lambda: defaultdict(int))
    
    for true_label, pred_label in zip(all_true_labels, all_pred_labels):
        confusion_matrix[true_label][pred_label] += 1
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    all_persons = list(set(all_true_labels))
    print(f"\nüìä Confusion Matrix (Confidence‚â•{CONFIDENCE_THRESHOLD}%, Gap‚â•{MIN_CONFIDENCE_GAP}%):")
    print("="*60)
    
    total_correct = 0
    total_samples = 0
    
    for person in all_persons:
        correct = confusion_matrix[person][person]
        unknown = confusion_matrix[person]["Unknown"]
        wrong = sum(confusion_matrix[person][other] for other in confusion_matrix[person] 
                   if other != person and other != "Unknown")
        
        total = correct + unknown + wrong
        accuracy = (correct/total)*100 if total > 0 else 0
        
        print(f"üë§ {person:12} | Correct: {correct:2d} | Unknown: {unknown:2d} | Wrong: {wrong:2d} | Acc: {accuracy:5.1f}%")
        
        total_correct += correct
        total_samples += total
    
    overall_accuracy = (total_correct/total_samples)*100 if total_samples > 0 else 0
    
    print("="*60)
    print(f"üéØ Overall Recognition Rate: {total_correct}/{total_samples} = {overall_accuracy:.1f}%")
    print(f"üìà Average Confidence: {np.mean(all_confidences):.1f}%")
    
    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    if overall_accuracy >= 95:
        print("üéâ Excellent! System is ready for production.")
    elif overall_accuracy >= 85:
        print("üëç Good performance. Consider fine-tuning thresholds.")
    else:
        print("‚ö†Ô∏è  Needs improvement:")
        print("   ‚Ä¢ Collect more diverse training images")
        print("   ‚Ä¢ Adjust confidence/gap thresholds") 
        print("   ‚Ä¢ Retrain with better parameters")

def main():
    global CONFIDENCE_THRESHOLD, MIN_CONFIDENCE_GAP
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset directory
    try:
        os.makedirs(dataset_path, exist_ok=True)
    except Exception as e:
        print(f"‚ùå Error creating dataset directory: {e}")
        return

    while True:
        print("\n" + "="*70)
        print("ü§ñ ENHANCED MULTI-PERSON FACE RECOGNITION SYSTEM")
        print("="*70)
        print("1. üì∑ Capture new faces")
        print("2. üß† Train the model")
        print("3. üîç Multi-person recognition (Enhanced)")
        print("4. üß™ Basic model test")
        print("5. üî¨ Advanced model test")
        print("6. üìä View dataset summary")
        print("7. ‚öôÔ∏è  Adjust thresholds")
        print("8. üéöÔ∏è  Live threshold adjustment")
        print("9. üóëÔ∏è  Delete person data")
        print("10. üö™ Exit")
        print("="*70)
        print(f"Current Settings - Confidence: {CONFIDENCE_THRESHOLD}% | Gap: {MIN_CONFIDENCE_GAP}%")
        
        choice = input("Enter your choice (1-10): ").strip()

        choice = input("Enter your choice (1-10): ").strip()

        if choice == '1':
            capture_faces()
        elif choice == '2':
            train_model()
        elif choice == '3':
            recognize_faces()
        elif choice == '4':
            test_model()
        elif choice == '5':
            advanced_test()
        elif choice == '6':
            view_dataset()
        elif choice == '7':
            adjust_threshold()
        elif choice == '8':
            live_adjustment()
        elif choice == '9':
            delete_person_data()
        elif choice == '10':
            print("üëã Thank you for using Enhanced Face Recognition System!")
            print("\nüî• SYSTEM PERFORMANCE TIPS:")
            print("="*50)
            print("üì∏ Data Collection:")
            print("   ‚Ä¢ Collect 300+ images per person")
            print("   ‚Ä¢ Use varied lighting conditions")
            print("   ‚Ä¢ Include different facial expressions")
            print("   ‚Ä¢ Capture from multiple angles")
            print("   ‚Ä¢ Ensure consistent image quality")
            print("\n‚öôÔ∏è  Threshold Settings:")
            print("   ‚Ä¢ Higher confidence = More strict recognition")
            print("   ‚Ä¢ Higher gap = Better unknown detection")
            print("   ‚Ä¢ Balance based on your environment")
            print("\nüéØ Multi-Person Features:")
            print("   ‚Ä¢ System tracks up to 10 faces simultaneously")
            print("   ‚Ä¢ Each person gets unique ID for tracking")
            print("   ‚Ä¢ Stability checking prevents false positives")
            print("   ‚Ä¢ Individual prediction buffers per person")
            print(f"\nüíæ Your final settings:")
            print(f"   Confidence Threshold: {CONFIDENCE_THRESHOLD}%")
            print(f"   Confidence Gap Threshold: {MIN_CONFIDENCE_GAP}%")
            print("\n‚ú® System ready for production use!")
            break
        else:
            print("‚ùå Invalid input. Please enter a number 1‚Äì10.")

def system_info():
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"""
    print("\nüñ•Ô∏è  SYSTEM INFORMATION")
    print("="*50)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö OpenCV
    try:
        print(f"‚úÖ OpenCV version: {cv2.__version__}")
    except:
        print("‚ùå OpenCV not found!")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö TensorFlow
    try:
        import tensorflow as tf
        print(f"‚úÖ TensorFlow version: {tf.__version__}")
    except:
        print("‚ùå TensorFlow not found!")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Camera
    cap_test = cv2.VideoCapture(camera_index)
    if cap_test.isOpened():
        print(f"‚úÖ Camera {camera_index} available")
        cap_test.release()
    else:
        print(f"‚ùå Camera {camera_index} not available")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Haar Cascade
    if os.path.exists(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'):
        print("‚úÖ Haar Cascade face detector loaded")
    else:
        print("‚ùå Haar Cascade face detector not found!")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Dataset
    if os.path.exists(dataset_path):
        persons = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
        total_images = sum([len([f for f in os.listdir(os.path.join(dataset_path, p)) 
                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) 
                           for p in persons])
        print(f"‚úÖ Dataset: {len(persons)} persons, {total_images} images")
    else:
        print("‚ùå Dataset directory not found")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Model
    if os.path.exists("face_recognition_model.keras"):
        print("‚úÖ Trained model found")
    else:
        print("‚ùå No trained model found")
    
    if os.path.exists("label_encoder.pkl"):
        print("‚úÖ Label encoder found")
    else:
        print("‚ùå No label encoder found")
    
    print("="*50)
    print("üéöÔ∏è  Current Thresholds:")
    print(f"   Confidence: {CONFIDENCE_THRESHOLD}%")
    print(f"   Gap: {MIN_CONFIDENCE_GAP}%")
    print(f"   Stability frames: {MIN_STABILITY_FRAMES}")
    print("="*50)

if __name__ == "__main__":
    print("üöÄ Starting Enhanced Face Recognition System...")
    print("üîß Performing system checks...")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
    system_requirements_ok = True
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö OpenCV
    try:
        cv2_version = cv2.__version__
        print(f"‚úÖ OpenCV {cv2_version} detected")
    except:
        print("‚ùå OpenCV not found! Please install: pip install opencv-python")
        system_requirements_ok = False
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö TensorFlow
    try:
        import tensorflow as tf
        tf_version = tf.__version__
        print(f"‚úÖ TensorFlow {tf_version} detected")
    except:
        print("‚ùå TensorFlow not found! Please install: pip install tensorflow")
        system_requirements_ok = False
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö sklearn
    try:
        import sklearn
        print(f"‚úÖ scikit-learn {sklearn.__version__} detected")
    except:
        print("‚ùå scikit-learn not found! Please install: pip install scikit-learn")
        system_requirements_ok = False
    
    if not system_requirements_ok:
        print("‚ùå System requirements not met. Please install missing packages.")
        exit(1)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö camera
    print("üìπ Testing camera...")
    cap_test = cv2.VideoCapture(camera_index)
    if cap_test.isOpened():
        print(f"‚úÖ Camera {camera_index} is working")
        cap_test.release()
    else:
        print(f"‚ö†Ô∏è  Camera {camera_index} not available")
        print("   Face capture will not work, but you can still train/test with existing data")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Haar Cascade
    cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
    if os.path.exists(cascade_path):
        print("‚úÖ Face detection model loaded successfully")
    else:
        print("‚ùå Haar Cascade file not found!")
        system_requirements_ok = False
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset directory
    try:
        os.makedirs(dataset_path, exist_ok=True)
        print(f"‚úÖ Dataset directory ready: {dataset_path}")
    except Exception as e:
        print(f"‚ùå Cannot create dataset directory: {e}")
        print("Please check path permissions and try again.")
        system_requirements_ok = False
    
    if not system_requirements_ok:
        print("‚ùå Critical system requirements not met. Exiting...")
        exit(1)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö
    existing_persons = 0
    existing_images = 0
    
    if os.path.exists(dataset_path):
        persons = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
        existing_persons = len(persons)
        existing_images = sum([len([f for f in os.listdir(os.path.join(dataset_path, p)) 
                                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) 
                              for p in persons])
    
    if existing_persons > 0:
        print(f"üìä Found existing dataset: {existing_persons} persons, {existing_images} images")
    else:
        print("üìä No existing dataset found - ready for new data collection")
    
    if os.path.exists("face_recognition_model.keras"):
        print("üß† Trained model found - ready for recognition")
    else:
        print("üß† No trained model - you'll need to train after collecting data")
    
    print("\n" + "="*70)
    print("üéØ ENHANCED FEATURES:")
    print("‚ú® Multi-person simultaneous recognition")
    print("üîç Advanced unknown detection with confidence gap analysis") 
    print("üìä Individual face tracking with stability checking")
    print("‚öôÔ∏è  Real-time threshold adjustment")
    print("üß™ Comprehensive model testing and analysis")
    print("="*70)
    
    print(f"\nüéöÔ∏è  Default Settings:")
    print(f"   Confidence Threshold: {CONFIDENCE_THRESHOLD}%")
    print(f"   Confidence Gap Threshold: {MIN_CONFIDENCE_GAP}%")
    print(f"   Stability Frames Required: {MIN_STABILITY_FRAMES}")
    
    print("\nüöÄ System initialization complete! Starting main menu...")
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ main function
    main()
