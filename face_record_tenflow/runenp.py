import face_recognition
import cv2
import os
import numpy as np
import pickle
from tensorflow.keras.models import load_model

# --- âš™ï¸ Main Configurations âš™ï¸ ---
# à¸ªà¸£à¹‰à¸²à¸‡ Path à¹à¸šà¸šà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹€à¸žà¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”
BASE_DIR = os.path.dirname(os.path.realpath(__file__))

# 1. Paths for Recognition
ENCODINGS_FILE = os.path.join(BASE_DIR, "encodings.pkl")

# 2. Paths for Face Detection (OpenCV's DNN Model)
PROTOTXT_PATH = os.path.join(BASE_DIR, "liveness_model", "deploy.prototxt")
WEIGHTS_PATH = os.path.join(BASE_DIR, "liveness_model", "res10_300x300_ssd_iter_140000.caffemodel")

# 3. Path for Liveness Detection Model
LIVENESS_MODEL_PATH = os.path.join(BASE_DIR, "liveness_model", "liveness.model")

# --- Model Parameters ---
RECOGNITION_TOLERANCE = 0.5  # à¹€à¸à¸“à¸‘à¹Œà¸à¸²à¸£à¸¢à¸­à¸¡à¸£à¸±à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸² (à¸„à¹ˆà¸²à¸¢à¸´à¹ˆà¸‡à¸™à¹‰à¸­à¸¢ à¸¢à¸´à¹ˆà¸‡à¹€à¸‚à¹‰à¸¡à¸‡à¸§à¸”)
LIVENESS_CONFIDENCE_THRESHOLD = 0.9 # à¹€à¸à¸“à¸‘à¹Œà¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸„à¸™à¸ˆà¸£à¸´à¸‡ (à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸ªà¸¹à¸‡à¹†)
FACE_DETECTION_CONFIDENCE = 0.6 # à¹€à¸à¸“à¸‘à¹Œà¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¹ƒà¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²

# ==================== ðŸš€ 1. à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” ðŸš€ ====================

# --- à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥ Face Recognition ---
print("[INFO] à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸šà¸«à¸™à¹‰à¸² (encodings.pkl)...")
if not os.path.exists(ENCODINGS_FILE):
    print(f"âŒ ERROR: à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œ '{ENCODINGS_FILE}' à¸à¸£à¸¸à¸“à¸²à¸£à¸±à¸™ 'create_encodings.py' à¸à¹ˆà¸­à¸™")
    exit()
with open(ENCODINGS_FILE, "rb") as f:
    data = pickle.load(f)
known_encodings = data["encodings"]
known_names = data["names"]

# --- à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥ OpenCV Face Detector ---
print("[INFO] à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸² (OpenCV DNN)...")
if not os.path.exists(PROTOTXT_PATH) or not os.path.exists(WEIGHTS_PATH):
    print("âŒ ERROR: à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹‚à¸¡à¹€à¸”à¸¥à¸‚à¸­à¸‡ OpenCV Face Detector")
    exit()
face_net = cv2.dnn.readNet(PROTOTXT_PATH, WEIGHTS_PATH)

# --- à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥ Liveness Detection ---
print("[INFO] à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²à¸ˆà¸£à¸´à¸‡ (Liveness)...")
if not os.path.exists(LIVENESS_MODEL_PATH):
    print(f"âŒ ERROR: à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œ '{LIVENESS_MODEL_PATH}'")
    exit()
liveness_net = load_model(LIVENESS_MODEL_PATH)


# ==================== ðŸŽ¥ 2. à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™ ðŸŽ¥ ====================
print("\nâœ… à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™! à¹€à¸£à¸´à¹ˆà¸¡à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡...")
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("âŒ ERROR: à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸›à¸´à¸”à¸à¸¥à¹‰à¸­à¸‡à¹„à¸”à¹‰")
    exit()

print("âœ… à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²à¹à¸šà¸š Real-time... (à¸à¸” 'q' à¹€à¸žà¸·à¹ˆà¸­à¸­à¸­à¸)")

while True:
    ret, frame = cap.read()
    if not ret: break
    frame = cv2.flip(frame, 1)
    (h, w) = frame.shape[:2]

    # â­ï¸ à¹ƒà¸Šà¹‰ OpenCV DNN à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¹ƒà¸šà¸«à¸™à¹‰à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¹€à¸Ÿà¸£à¸¡
    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
    face_net.setInput(blob)
    detections = face_net.forward()

    # à¸§à¸™à¸¥à¸¹à¸›à¹ƒà¸šà¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹„à¸”à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
    for i in range(0, detections.shape[2]):
        confidence = detections[0, 0, i, 2]

        if confidence > FACE_DETECTION_CONFIDENCE:
            # à¸„à¸³à¸™à¸§à¸“à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸‚à¸­à¸‡à¸à¸£à¸­à¸šà¸£à¸­à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            startX, startY = max(0, startX), max(0, startY)
            endX, endY = min(w - 1, endX), min(h - 1, endY)
            
            # ================= STAGE 1: LIVENESS CHECK =================
            face_roi = frame[startY:endY, startX:endX]
            if face_roi.size == 0: continue

            # Preprocess the face for the liveness model
            face_for_liveness = cv2.resize(face_roi, (32, 32))
            face_for_liveness = face_for_liveness.astype("float") / 255.0
            face_for_liveness = np.expand_dims(face_for_liveness, axis=0)
            
            # Predict liveness
            preds = liveness_net.predict(face_for_liveness, verbose=0)[0]
            j = np.argmax(preds)
            liveness_label = 'spoof' if j == 1 else 'real'
            liveness_confidence = preds[j]

            # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸œà¸¥
            display_name = ""
            box_color = (0, 255, 255) # à¸ªà¸µà¹€à¸«à¸¥à¸·à¸­à¸‡ (Checking...)
            
            # ================= STAGE 2: FACE RECOGNITION (IF REAL) =================
            if liveness_label == 'real' and liveness_confidence > LIVENESS_CONFIDENCE_THRESHOLD:
                # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸„à¸™à¸ˆà¸£à¸´à¸‡ à¹ƒà¸«à¹‰à¹€à¸£à¸´à¹ˆà¸¡à¸£à¸°à¸šà¸¸à¸•à¸±à¸§à¸•à¸™
                
                # Convert frame for face_recognition library
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # Convert OpenCV box to face_recognition box format (top, right, bottom, left)
                face_location_dlib = [(startY, endX, endY, startX)]
                
                current_face_encoding = face_recognition.face_encodings(rgb_frame, face_location_dlib)

                name = "Unknown"
                if len(current_face_encoding) > 0:
                    matches = face_recognition.compare_faces(known_encodings, current_face_encoding[0], tolerance=RECOGNITION_TOLERANCE)
                    face_distances = face_recognition.face_distance(known_encodings, current_face_encoding[0])
                    
                    if len(face_distances) > 0:
                        best_match_index = np.argmin(face_distances)
                        if matches[best_match_index] and face_distances[best_match_index] < RECOGNITION_TOLERANCE:
                            name = known_names[best_match_index]
                
                # à¸à¸³à¸«à¸™à¸”à¸ªà¸µà¹à¸¥à¸°à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸•à¸²à¸¡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
                if name != "Unknown":
                    display_name = f"{name}"
                    box_color = (0, 255, 0) # à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§ (Known Person)
                else:
                    display_name = "Unknown (Real)"
                    box_color = (0, 165, 255) # à¸ªà¸µà¸ªà¹‰à¸¡ (Unknown Person)
            
            else: # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸‚à¸­à¸‡à¸›à¸¥à¸­à¸¡ (SPOOF)
                display_name = f"SPOOF ({liveness_confidence:.2f})"
                box_color = (0, 0, 255) # à¸ªà¸µà¹à¸”à¸‡ (SPOOF)
            
            # --- à¸§à¸²à¸”à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸¥à¸‡à¸šà¸™à¹€à¸Ÿà¸£à¸¡ ---
            cv2.putText(frame, display_name, (startX, startY - 10), cv2.FONT_HERSHEY_DUPLEX, 0.7, box_color, 2)
            cv2.rectangle(frame, (startX, startY), (endX, endY), box_color, 2)

    cv2.imshow("Face Recognition with Liveness Detection - By Tawan", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print("Program terminated.")